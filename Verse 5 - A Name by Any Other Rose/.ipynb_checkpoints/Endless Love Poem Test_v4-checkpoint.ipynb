{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d6c019c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --prefix {sys.prefix} -y -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5b3ecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\weber\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\weber\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\weber\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\weber\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c327cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cd686cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68e0808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the text generation pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d05d17c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Two roads diverged in a yellow wood, and one man with a knife was injured in both incidents.\\n\\n\\n\\n\\n\\n\\nA 21-year-old man was wounded in a parking lot in the city of Nisar on Tuesday'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Two roads diverged in a yellow wood, and\")[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ead3d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialogue generation function with temperature\n",
    "def generate_line(previous_line, macro_context, max_tokens=30, temperature=1.0):\n",
    "    # Construct the prompt combining macro context and the last spoken line\n",
    "    prompt = f\"{macro_context}  who just said: '{previous_line}'. My response is:\"\n",
    "    # Generate with specific temperature\n",
    "    generated = generator(prompt, max_length=len(tokenizer.encode(prompt)) + max_tokens, num_return_sequences=1, temperature=temperature)\n",
    "    # Extract the new line, stripping the setup part and any extra whitespace\n",
    "    new_line = generated[0]['generated_text'][len(prompt):].strip()\n",
    "    new_line = new_line.split('\\n')[0]  # Get only the first new line generated\n",
    "    return new_line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f37103a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "last_spoken_line = \"\"\n",
    "turns = 5  # 5 lines each\n",
    "dialogue = \"\"\n",
    "\n",
    "# Contexts for both characters\n",
    "girl_macro_context = \"Context: I'm a girl & I'm flirting with this guy\"\n",
    "guy_macro_context = \"Context: I'm a guy and I'm not interested in this girl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4cbe9034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Generating the poem with a specific temperature setting\n",
    "for i in range(turns):\n",
    "    # Girl bot speaks\n",
    "    girl_line = generate_line(last_spoken_line, girl_macro_context, temperature=1.0)  \n",
    "    dialogue += \"Girl: \" + girl_line + '\\n'\n",
    "    last_spoken_line = girl_line\n",
    "    \n",
    "    # Guy bot responds\n",
    "    guy_line = generate_line(last_spoken_line, guy_macro_context, temperature=1.0)  \n",
    "    dialogue += \"Guy: \" + guy_line + '\\n'\n",
    "    last_spoken_line = guy_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bb9e7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girl: You're trying it but that will work no matter WHAT else we've been told from him. As such, any suggestion being used for this has no\n",
      "Guy: This girl IS going to get caught in that big lie' ~~=<=<<< >@LaviaRi is very kind\n",
      "Girl: 'I'm in no place whatsoever telling why she can go there without permission and so I do NOT HAVE HER AT all. She just has no option\n",
      "Guy: ''It gets harder as you get older who's going through those problems; and every problem goes back at least until the early middle-middle thirt\n",
      "Girl: The two sexes are on par and don't actually get the same relationship if and only if the problem ever came. As for whether we'll agree with\n",
      "Guy: 'This isn't that it really is about one couple that'll make an affair on top'\n",
      "Girl: Don't just talk like this. If this guy wants someone to feel \"hot out here who's going to want his attention? What'll happen to\n",
      "Guy: it'll leave this girl frustrated over where that's not gonna happen to her â€“ not how badly anyone cares! People are having these sorta emotions in\n",
      "Girl: Is he the good man we all wanted to marry? They all say that's great? What other guy's going by an argument for having to ask\n",
      "Guy: No: NO!\n",
      "Girl: 'I got to talk to you,' but no.\n",
      "Guy: ''She should talk to her, and if she wants your help then feel free to talk to me, you can do that.'\n",
      "Girl: \"I have an affair with you and a mutual friend. I have an affair. There's nothing I can do and no one can do.''\n",
      "Guy: ''It's very interesting to see how much the world reacts like a dog. My parents always treat me. They treat me very nicely and in the\n",
      "Girl: 'I wouldn't mind the pain if...' I said if I could have done something in an instant and I had something new and a different opinion\n",
      "Guy: ''My whole life is in danger, so I wish I wasn't thinking about it in a way so I would have let things sink in.' If\n",
      "Girl: \"Okay, OK, if I'm like that, I'll still be alright. But I'm sorry.\"\n",
      "Guy: I'm being rude, I'm being rude and being polite and we'll still be friends.\"\n",
      "Girl: 'This is bad. I'm having to watch this guy. He is a slut.' No one else is hurt and it can't stop, so\n",
      "Guy: ''No. There's a great deal of hate and anger and anger at us. I can put on a lot of hats. I think every time\n",
      "Girl: 'Look, he's really just another one. And I thought he thought 'No, he's really different than me.' He said so. And\n",
      "Guy: 'Oh yeah. And he's a normal guy.' So I think I just wanted to see if he understood the things people get about him and try\n",
      "Girl: ''I just said to some of our friends and we're going to talk about it. And he was very open and honest. ''I just said\n",
      "Guy: ''He took away our kids, I couldn't wait to leave them, so I thought it was not so good to go ahead and I was like\n",
      "Girl: ''He took away our kids and we were talking about how much he was going on with the girls.''\n",
      "Guy: ''I'm sorry, we're back and they're not in the room''.\n",
      "Girl: \"Why are you making me want to play your game?' ''\n",
      "Guy: 'Because I'm a girl, but because I have been a girl for ages, I haven't been to much trouble myself'. In fact,\n",
      "Girl: 'I know how to get away with an adult who does stuff that nobody else is able to do, I am just trying to get away. It\n",
      "Guy: ''If you're going to have to get away with an adult, I hope you were able to. I need to step back from this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673de20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
